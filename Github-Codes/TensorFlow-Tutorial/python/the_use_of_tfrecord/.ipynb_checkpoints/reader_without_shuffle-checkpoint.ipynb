{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"tfrecord_data/ParseSingleExample/Squeeze_X:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"tfrecord_data/ParseSingleExample/Squeeze_y:0\", shape=(), dtype=int64)\n",
      "** batch 0\n",
      "('_y_batch:', array([0, 1, 2, 3]))\n",
      "** batch 1\n",
      "('_y_batch:', array([4, 5, 6, 7]))\n",
      "** batch 2\n",
      "('_y_batch:', array([ 9,  8, 10, 11]))\n",
      "** batch 3\n",
      "('_y_batch:', array([12, 13, 15, 14]))\n",
      "** batch 4\n",
      "('_y_batch:', array([16, 17, 18, 19]))\n",
      "** batch 5\n",
      "('_y_batch:', array([20, 21, 23, 22]))\n",
      "** batch 6\n",
      "('_y_batch:', array([24, 25, 26, 27]))\n",
      "** batch 7\n",
      "('_y_batch:', array([28, 29, 30, 31]))\n",
      "** batch 8\n",
      "('_y_batch:', array([32, 33, 34, 35]))\n",
      "** batch 9\n",
      "('_y_batch:', array([36, 38, 39, 37]))\n",
      "** batch 10\n",
      "('_y_batch:', array([40, 41, 42, 43]))\n",
      "** batch 11\n",
      "('_y_batch:', array([44, 45, 46, 47]))\n",
      "** batch 12\n",
      "('_y_batch:', array([48, 49,  0,  1]))\n",
      "** batch 13\n",
      "('_y_batch:', array([3, 2, 4, 5]))\n",
      "** batch 14\n",
      "('_y_batch:', array([7, 6, 8, 9]))\n",
      "** batch 15\n",
      "('_y_batch:', array([10, 11, 12, 13]))\n",
      "** batch 16\n",
      "('_y_batch:', array([15, 14, 17, 16]))\n",
      "** batch 17\n",
      "('_y_batch:', array([19, 18, 21, 20]))\n",
      "** batch 18\n",
      "('_y_batch:', array([23, 22, 24, 25]))\n",
      "** batch 19\n",
      "('_y_batch:', array([26, 27, 28, 29]))\n",
      "** batch 20\n",
      "('_y_batch:', array([30, 31, 32, 33]))\n",
      "** batch 21\n",
      "('_y_batch:', array([34, 36, 35, 37]))\n",
      "** batch 22\n",
      "('_y_batch:', array([38, 40, 39, 42]))\n",
      "** batch 23\n",
      "('_y_batch:', array([41, 44, 43, 45]))\n",
      "** batch 24\n",
      "('_y_batch:', array([47, 46, 49, 48]))\n",
      "FIFOQueue '_2_tfrecord_data/batch/fifo_queue' is closed and has insufficient elements (requested 4, current size 0)\n",
      "\t [[Node: tfrecord_data/batch = QueueDequeueUpToV2[component_types=[DT_FLOAT, DT_INT64], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](tfrecord_data/batch/fifo_queue, tfrecord_data/batch/n)]]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 9, 8, 10, 11, 12, 13, 15, 14, 16, 17, 18, 19, 20, 21, 23, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 0, 1, 3, 2, 4, 5, 7, 6, 8, 9, 10, 11, 12, 13, 15, 14, 17, 16, 19, 18, 21, 20, 23, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 35, 37, 38, 40, 39, 42, 41, 44, 43, 45, 47, 46, 49, 48]\n"
     ]
    }
   ],
   "source": [
    "# -*- coding:utf-8 -*- \n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "'''read data.\n",
    "without shuffle, for validation or test data.\n",
    "'''\n",
    "\n",
    "# output file name string to a queue\n",
    "with tf.variable_scope('tfrecord_data'):\n",
    "    filename_queue = tf.train.string_input_producer(['../data/test1.tfrecord', '../data/test2.tfrecord'], num_epochs=None,\n",
    "                                                    shuffle=False)\n",
    "    # create a reader from file queue\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    # get feature from serialized example\n",
    "    features = tf.parse_single_example(serialized_example,\n",
    "                                       features={\n",
    "                                           'X': tf.FixedLenFeature([2], tf.float32),\n",
    "                                           'y': tf.FixedLenFeature([], tf.int64)}\n",
    "                                       )\n",
    "    X_out = features['X']\n",
    "    y_out = features['y']\n",
    "\n",
    "    print(X_out)\n",
    "    print(y_out)\n",
    "    X_batch, y_batch = tf.train.batch([X_out, y_out],\n",
    "                                      batch_size=4,\n",
    "                                      capacity=10,\n",
    "                                      num_threads=2,\n",
    "                                      allow_smaller_final_batch=True)\n",
    "    new_ops = [v for v in tf.global_variables() if v.name.startswith(vs.name + '/')]\n",
    "    \n",
    "sess = tf.Session()\n",
    "# init = tf.global_variables_initializer()\n",
    "init = tf.group(tf.global_variables_initializer(),\n",
    "                   tf.local_variables_initializer())\n",
    "sess.run(init)\n",
    "\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "y_outputs = list()\n",
    "for i in xrange(30):\n",
    "    try:\n",
    "        _X_batch, _y_batch = sess.run([X_batch, y_batch])\n",
    "        print('** batch %d' % i)\n",
    "        print('_y_batch:', _y_batch)\n",
    "        y_outputs.extend(_y_batch.tolist())\n",
    "    except tf.errors.OutOfRangeError, e:\n",
    "        print(e.message)\n",
    "        break\n",
    "print(y_outputs)\n",
    "\n",
    "coord.request_stop()\n",
    "coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.train.Coordinator?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIFOQueue '_2_tfrecord_data/batch/fifo_queue' is closed and has insufficient elements (requested 4, current size 0)\n",
      "\t [[Node: tfrecord_data/batch = QueueDequeueUpToV2[component_types=[DT_FLOAT, DT_INT64], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](tfrecord_data/batch/fifo_queue, tfrecord_data/batch/n)]]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "y_outputs = list()\n",
    "sess.run(tf.variables_initializer(new_ops))\n",
    "coord1 = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess=sess, coord=coord1)\n",
    "for i in xrange(30):\n",
    "    try:\n",
    "        _X_batch, _y_batch = sess.run([X_batch, y_batch])\n",
    "        print('** batch %d' % i)\n",
    "        print('_y_batch:', _y_batch)\n",
    "        y_outputs.extend(_y_batch.tolist())\n",
    "    except tf.errors.OutOfRangeError, e:\n",
    "        print(e.message)\n",
    "        break\n",
    "print(y_outputs)\n",
    "print(sorted(y_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
